
if_gpu: 1
if_amp: 1
data_set_name : "train_corpus_c4_v2"
device_id: [6,7]
model_name: "gpt3"
n_attention_layer: 32
rms_norm_eps : 1e-6
n_hidden_size: 768
n_intermediate_size : 512
n_head: 16
n_head_dim: 32
mlp_bias : False
vocab_size: 20833
max_token: 512
max_gen_token: 150
n_batch_size: 24
n_epoch: 10
learning_rate: 0.0005
resid_pdrop: 0.1
attn_pdrop: 0.1
save_per_batchs: 2000
if_train: 1
temperature: 0.75
top_k: 8  
output_path: "./pt/pt_32l_0_00025_AdamW_c4_v10"
pretrain_model : ""
wlist : "./data/vocab.list.c4.v2"
wlist_size : 20833
log_file : "./logs/train.log"
